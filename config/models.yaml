models:
  small:
    name: "qwen2.5:7b"
    purpose: "routing, simple queries"
    max_tokens: 4096
    temperature: 0.7
    
  large:
    name: "qwen2.5-coder:32b"
    purpose: "complex coding tasks"
    max_tokens: 32768
    temperature: 0.1
    
  embedding:
    name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cpu"  # or "cuda" if you have GPU space

  embedding_high_quality:
    name: "mxbai-embed-large"
    device: "cuda"  # Use GPU for best performance

  multimodal:
    name: "llama4:16x17b"
    purpose: "memory analysis, architecture, planning"
    max_tokens: 1048576
    temperature: 0.2

  gooseai:
    name: "gooseai/gpt-neo-20b"
    purpose: "agentic work, external API"
    max_tokens: 2048
    temperature: 0.7
    api_base_url: "${GOOSEAI_API_BASE_URL}"

ollama:
  base_url: "http://localhost:11434"
  timeout: 300
  max_retries: 3

# Additional models for testing
additional_models:
  llama4_16x17b:
    name: "llama4:16x17b"
    purpose: "testing, large language model"
  qwen3_30b_a3b:
    name: "qwen3:30b-a3b"
    purpose: "testing, large language model"
  qwen2_5_coder_32b:
    name: "qwen2.5-coder:32b"
    purpose: "testing, large coding model"
